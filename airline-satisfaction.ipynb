{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n%matplotlib inline\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T17:54:43.766017Z","iopub.execute_input":"2022-07-25T17:54:43.766492Z","iopub.status.idle":"2022-07-25T17:54:43.805722Z","shell.execute_reply.started":"2022-07-25T17:54:43.766386Z","shell.execute_reply":"2022-07-25T17:54:43.804711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T01:38:55.055939Z","iopub.execute_input":"2022-07-25T01:38:55.057109Z","iopub.status.idle":"2022-07-25T01:38:55.533894Z","shell.execute_reply.started":"2022-07-25T01:38:55.057052Z","shell.execute_reply":"2022-07-25T01:38:55.53277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.info())\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T00:40:48.613165Z","iopub.execute_input":"2022-07-25T00:40:48.613546Z","iopub.status.idle":"2022-07-25T00:40:48.826872Z","shell.execute_reply.started":"2022-07-25T00:40:48.613514Z","shell.execute_reply":"2022-07-25T00:40:48.825612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Univariate analysis\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfor c in train.columns:\n    if train[c].dtype in ['object','bool']: #categorical column\n        plt.figure()\n        sns.countplot(train[c],palette='magma')\n        plt.show()\n    else: #numerical column\n        plt.figure()\n        sns.histplot(train[c],kde=(len(train[c].unique())>10),color='purple')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:07.242761Z","iopub.execute_input":"2022-07-22T20:40:07.243195Z","iopub.status.idle":"2022-07-22T20:40:32.494758Z","shell.execute_reply.started":"2022-07-22T20:40:07.243141Z","shell.execute_reply":"2022-07-22T20:40:32.492728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sns.pairplot(train, hue=train.columns[-1],palette='viridis') #too many variables to be very helpful\nplt.figure(figsize=(20, 10))\nsns.heatmap(train.corr(), annot=True, vmin=-1, vmax=1, cmap=\"coolwarm\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:32.496663Z","iopub.execute_input":"2022-07-22T20:40:32.497429Z","iopub.status.idle":"2022-07-22T20:40:35.159882Z","shell.execute_reply.started":"2022-07-22T20:40:32.497386Z","shell.execute_reply":"2022-07-22T20:40:35.158867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bivariate analysis\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncount = 0\nfor c in train.columns:\n    if (train[c].dtype in ['object','bool']) or (count>=4): #categorical column\n        plt.figure()\n        sns.countplot(data=train,x=c,hue=train.columns[-1],palette='dark')\n        plt.show()\n    else: #numerical column\n        count+=1\n        plt.figure()\n        sns.histplot(data=train,x=c,hue=train.columns[-1],element='step',palette='dark')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T01:39:02.392907Z","iopub.execute_input":"2022-07-25T01:39:02.393324Z","iopub.status.idle":"2022-07-25T01:39:22.290685Z","shell.execute_reply.started":"2022-07-25T01:39:02.39329Z","shell.execute_reply":"2022-07-25T01:39:22.289203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings #preprocessing\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/airline-passenger-satisfaction/test.csv\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nytrain=train['satisfaction']\nytest=test['satisfaction']\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntest.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\n#plt.figure(figsize=(20, 10))\n#sns.heatmap(train.corr(), annot=True, vmin=-1, vmax=1, cmap=\"icefire\")\n#plt.show()\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:46.553354Z","iopub.execute_input":"2022-07-22T20:40:46.554095Z","iopub.status.idle":"2022-07-22T20:40:47.085885Z","shell.execute_reply.started":"2022-07-22T20:40:46.554046Z","shell.execute_reply":"2022-07-22T20:40:47.084283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:47.087498Z","iopub.execute_input":"2022-07-22T20:40:47.087888Z","iopub.status.idle":"2022-07-22T20:40:47.100387Z","shell.execute_reply.started":"2022-07-22T20:40:47.087854Z","shell.execute_reply":"2022-07-22T20:40:47.098263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logs=['Departure Delay in Minutes','Arrival Delay in Minutes'] #log transform due to distribution shape\nfor l in logs:\n    train[l] = np.log(1+train[l])\n    test[l] = np.log(1+test[l])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:47.102718Z","iopub.execute_input":"2022-07-22T20:40:47.103632Z","iopub.status.idle":"2022-07-22T20:40:47.129583Z","shell.execute_reply.started":"2022-07-22T20:40:47.10358Z","shell.execute_reply":"2022-07-22T20:40:47.128045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfor l in logs:\n    plt.figure(figsize=(10,5))\n    sns.histplot(train[l],color='orange')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:47.134694Z","iopub.execute_input":"2022-07-22T20:40:47.135134Z","iopub.status.idle":"2022-07-22T20:40:48.042207Z","shell.execute_reply.started":"2022-07-22T20:40:47.135097Z","shell.execute_reply":"2022-07-22T20:40:48.040764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntest =pd.get_dummies(test,drop_first=True)\ndisplay(train.head())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:48.043846Z","iopub.execute_input":"2022-07-22T20:40:48.044409Z","iopub.status.idle":"2022-07-22T20:40:48.180454Z","shell.execute_reply.started":"2022-07-22T20:40:48.044362Z","shell.execute_reply":"2022-07-22T20:40:48.179235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytrain=(ytrain=='satisfied').astype(int) #encoding ys\nytest=(ytest=='satisfied').astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:48.181989Z","iopub.execute_input":"2022-07-22T20:40:48.182379Z","iopub.status.idle":"2022-07-22T20:40:48.213954Z","shell.execute_reply.started":"2022-07-22T20:40:48.182345Z","shell.execute_reply":"2022-07-22T20:40:48.212543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(ytrain)\nplt.figure()\nsns.countplot(ytest)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:48.21571Z","iopub.execute_input":"2022-07-22T20:40:48.21724Z","iopub.status.idle":"2022-07-22T20:40:48.567364Z","shell.execute_reply.started":"2022-07-22T20:40:48.217161Z","shell.execute_reply":"2022-07-22T20:40:48.566043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.info()) #Arrival Delay in minutes is missing some values\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:48.568969Z","iopub.execute_input":"2022-07-22T20:40:48.569541Z","iopub.status.idle":"2022-07-22T20:40:48.607282Z","shell.execute_reply.started":"2022-07-22T20:40:48.569501Z","shell.execute_reply":"2022-07-22T20:40:48.605929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get rid of arrival delay due to extremely high correlation with departure delay\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntest.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:48.609091Z","iopub.execute_input":"2022-07-22T20:40:48.609591Z","iopub.status.idle":"2022-07-22T20:40:48.638516Z","shell.execute_reply.started":"2022-07-22T20:40:48.60955Z","shell.execute_reply":"2022-07-22T20:40:48.63714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#condensed preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/airline-passenger-satisfaction/test.csv\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nytrain=train['satisfaction']\nytest=test['satisfaction']\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntest.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\n\nlogs=['Departure Delay in Minutes','Arrival Delay in Minutes'] #log transform due to distribution shape\nfor l in logs:\n    train[l] = np.log(1+train[l])\n    test[l] = np.log(1+test[l])\ntrain=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntest =pd.get_dummies(test,drop_first=True)\nytrain=(ytrain=='satisfied').astype(int) #encoding ys\nytest=(ytest=='satisfied').astype(int)\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntest.drop('Arrival Delay in Minutes',axis=1,inplace=True)\nfrom sklearn.preprocessing import StandardScaler\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T01:39:22.293314Z","iopub.execute_input":"2022-07-25T01:39:22.294144Z","iopub.status.idle":"2022-07-25T01:39:22.946137Z","shell.execute_reply.started":"2022-07-25T01:39:22.294095Z","shell.execute_reply":"2022-07-25T01:39:22.945158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n#https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\nimport random\nrandom.seed(42)\nnames = [\n    \"LR\",\n    \"KNN\",\n    \"DTree\",\n    \"RF\",\n    \"ADA\",\n    \"NB\",\n    \"QDA\",\n]\n\nclassifiers = [\n    LogisticRegression(),\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n]\n\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)\nscores = []\nfor i,c in enumerate(classifiers):\n    c.fit(train,ytrain)\n    y_pred = c.predict(test)\n    f=f1_score(ytest, y_pred)\n    print([names[i],f])\n    scores.append(f)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:40:49.375027Z","iopub.execute_input":"2022-07-22T20:40:49.37542Z","iopub.status.idle":"2022-07-22T20:42:10.363144Z","shell.execute_reply.started":"2022-07-22T20:40:49.375386Z","shell.execute_reply":"2022-07-22T20:42:10.361753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.grid()\nplt.title(\"Base model performance\")\nsns.pointplot(names, scores)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:42:10.365162Z","iopub.execute_input":"2022-07-22T20:42:10.365939Z","iopub.status.idle":"2022-07-22T20:42:10.667641Z","shell.execute_reply.started":"2022-07-22T20:42:10.365887Z","shell.execute_reply":"2022-07-22T20:42:10.666348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nrandom.seed(42)\nparams = {\n    'base_estimator': [DecisionTreeClassifier(max_depth=3), DecisionTreeClassifier(max_depth=5),DecisionTreeClassifier()],\n    'n_estimators': [50,100,150],\n    'learning_rate' : [0.5,1]\n    \n}\nclf = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=params, scoring='f1',verbose=3)\nclf.fit(train,ytrain)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T20:42:10.669478Z","iopub.execute_input":"2022-07-22T20:42:10.670261Z","iopub.status.idle":"2022-07-22T21:07:42.662435Z","shell.execute_reply.started":"2022-07-22T20:42:10.670212Z","shell.execute_reply":"2022-07-22T21:07:42.661251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.best_params_\n#depth=5, lr=0.5, n=50, .952","metadata":{"execution":{"iopub.status.busy":"2022-07-22T21:07:42.66421Z","iopub.execute_input":"2022-07-22T21:07:42.664667Z","iopub.status.idle":"2022-07-22T21:07:42.673049Z","shell.execute_reply.started":"2022-07-22T21:07:42.664624Z","shell.execute_reply":"2022-07-22T21:07:42.671948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nparams = {\n    'base_estimator': [RandomForestClassifier()],\n    'n_estimators': [50,100,150,200,300,1000],\n    'learning_rate' : [0.5,1,1.5]\n}\ngrid = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=params, scoring='f1',verbose=3)\ngrid.fit(train,ytrain)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T21:07:42.674528Z","iopub.execute_input":"2022-07-22T21:07:42.675389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_\n#1.5,300,.957","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nparams = {\n    'base_estimator': [AdaBoostClassifier(base_estimator=RandomForestClassifier())],\n    'n_estimators': [50,100,150,200,300,1000],\n    'learning_rate' : [0.5,1]\n}\ngrid2 = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=params, scoring='f1',verbose=3)\ngrid2.fit(train,ytrain)\ngrid2.best_params_ # 0.5, 200","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nmodel = AdaBoostClassifier(base_estimator=RandomForestClassifier(),learning_rate=0.5,n_estimators=200)\nmodel.fit(train,ytrain)\ny_pred = model.predict(test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(ytest, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T02:57:02.744798Z","iopub.execute_input":"2022-07-25T02:57:02.746031Z","iopub.status.idle":"2022-07-25T02:57:41.542585Z","shell.execute_reply.started":"2022-07-25T02:57:02.745988Z","shell.execute_reply":"2022-07-25T02:57:41.541778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntrain['Departure Delay in Minutes'] = np.log(1+train[l])\ntrain=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\nplt.style.use('seaborn-dark-palette')\nplt.figure(figsize=(10,5))\npd.Series(model.feature_importances_, index=train.columns)[:10].sort_values().plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Base Model: \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/airline-passenger-satisfaction/test.csv\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nytrain=train['satisfaction']\nytest=test['satisfaction']\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntest.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\n\nlogs=['Departure Delay in Minutes','Arrival Delay in Minutes'] #log transform due to distribution shape\nfor l in logs:\n    train[l] = np.log(1+train[l])\n    test[l] = np.log(1+test[l])\ntrain=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntest =pd.get_dummies(test,drop_first=True)\nytrain=(ytrain=='satisfied').astype(int) #encoding ys\nytest=(ytest=='satisfied').astype(int)\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntest.drop('Arrival Delay in Minutes',axis=1,inplace=True)\nfrom sklearn.preprocessing import StandardScaler\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)\nx_train=train\nx_test=test\ny_train=ytrain\ny_test=ytest\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\n\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(\"Classification report:\")\nprint(classification_report(y_test, predictions))\naccuracy = accuracy_score(y_test,predictions)\nprint(\"Accuracy: \", accuracy)\nprint(\"Confusion matrix:\")\nprint(confusion_matrix(y_test, predictions))\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nprint(classification_report(y_test, predictions))\naccuracy = accuracy_score(y_test,predictions)\nprint(\"Accuracy: \", accuracy)\nprint(confusion_matrix(y_test, predictions))\n\n\n#Tuning: \nimport random\nfrom sklearn.model_selection import GridSearchCV \nrandom.seed(40)\nparams = {'criterion': ['gini', 'entropy'], \n          'splitter': ['best', 'random'], \n          'max_depth': [10, 20 ,50, 200, None]}\n\ngcv = GridSearchCV(estimator = DecisionTreeClassifier(),param_grid = params, scoring = 'f1', verbose = 3 )\ngcv.fit(x_test, y_test)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom.seed(42)\nrf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(train, ytrain)\n\ny_pred = rf_classifier.predict(test)\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(ytest, y_pred))\n\nfrom sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \n\nparam_grid = {\n    'max_depth': [80, 90, 100],\n    'n_estimators': [100, 200, 300],\n    'max_features': [2,3]\n}\n\nrandom.seed(42)\ngrid_search = GridSearchCV(estimator = rf_classifier, param_grid = param_grid, scoring= 'f1',verbose = 3)\n\ngrid_search.fit(train, ytrain)\nest_grid = grid_search.best_params_\n\nprint(est_grid)\n\nrf_classifier = RandomForestClassifier(random_state=42, max_depth= 80, n_estimators=300, max_features=3)\nrf_classifier.fit(train, ytrain)\n\ny_pred = rf_classifier.predict(test)\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(ytest, y_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL\n\nfrom sklearn.linear_model import LogisticRegression\n\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/airline-passenger-satisfaction/test.csv\")\nytrain=train['satisfaction']\nytest=test['satisfaction']\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntest.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\n\nlogs=['Departure Delay in Minutes','Arrival Delay in Minutes'] #log transform due to distribution shape\nfor l in logs:\n    train[l] = np.log(1+train[l])\n    test[l] = np.log(1+test[l])\ntrain=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntest =pd.get_dummies(test,drop_first=True)\nytrain=(ytrain=='satisfied').astype(int) #encoding ys\nytest=(ytest=='satisfied').astype(int)\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntest.drop('Arrival Delay in Minutes',axis=1,inplace=True)\nfrom sklearn.preprocessing import StandardScaler\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)\nimport random\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {'penalty':['l1','l2','elasticnet'],\n          'C':[0.01,0.1,0.2,0.3,0.5,0.7,1,1.2,1.5,2,3,5,10],\n             'solver':['saga']}\n\ngrid_search = GridSearchCV(estimator = LogisticRegression(),  \n                       param_grid = parameters,\n                       scoring = 'f1',\n                       verbose = 3)\n\ngrid_search.fit(train, ytrain)\nprint(grid_search.best_params_)\n\n# FINAL F1 SCORE: 0.8516424340333874\n\nfrom sklearn.metrics import f1_score\n\nf = f1_score(ytest, predictions)\nprint(\"Score\", f)\n\n# PARAMETERS USING MODEL COEFF FOR LOGREG\n\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntrain.drop(['satisfaction','Unnamed: 0','id'], axis = 1, inplace = True)\ntrain['Departure Delay in Minutes'] = np.log(1+train[l])\ntrain = pd.get_dummies(train, drop_first = True)\ntrain.drop('Arrival Delay in Minutes', axis = 1, inplace = True)\nplt.style.use('seaborn-dark-palette')\nplt.figure(figsize = (10,5))\npd.Series(model.coef_[0], index = train.columns)[:10].sort_values().plot(kind = 'barh')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T18:33:43.051022Z","iopub.execute_input":"2022-07-25T18:33:43.051413Z","iopub.status.idle":"2022-07-25T18:35:56.417875Z","shell.execute_reply.started":"2022-07-25T18:33:43.051382Z","shell.execute_reply":"2022-07-25T18:35:56.416778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN\nfrom sklearn.model_selection import GridSearchCV\nimport random\nrandom.seed(42)\nfrom sklearn.neighbors import KNeighborsClassifier\nparams = {\n    \"n_neighbors\" : [5,10,20,50,100,200],\n    \"weights\" : ['uniform','distance'],\n}\nclf = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=params, scoring='f1',verbose=3)\nclf.fit(train,ytrain)\nclf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-07-25T02:15:07.416148Z","iopub.execute_input":"2022-07-25T02:15:07.416569Z","iopub.status.idle":"2022-07-25T02:51:31.909293Z","shell.execute_reply.started":"2022-07-25T02:15:07.416535Z","shell.execute_reply":"2022-07-25T02:51:31.908115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=10, weights='distance')\nmodel.fit(train, ytrain)\ny_pred = model.predict(test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(ytest, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T02:53:52.80243Z","iopub.execute_input":"2022-07-25T02:53:52.802896Z","iopub.status.idle":"2022-07-25T02:54:48.451873Z","shell.execute_reply.started":"2022-07-25T02:53:52.802852Z","shell.execute_reply":"2022-07-25T02:54:48.450675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression(C=0.01, penalty= 'l1',solver= 'saga')\nmodel.fit(train, ytrain)\ny_pred = model.predict(test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(ytest, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T18:37:47.987506Z","iopub.execute_input":"2022-07-25T18:37:47.987894Z","iopub.status.idle":"2022-07-25T18:37:49.344767Z","shell.execute_reply.started":"2022-07-25T18:37:47.987865Z","shell.execute_reply":"2022-07-25T18:37:49.341177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#condensed preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv(\"../input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/airline-passenger-satisfaction/test.csv\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nytrain=train['satisfaction']\nytest=test['satisfaction']\ntrain.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\ntest.drop(['satisfaction','Unnamed: 0','id'],axis=1,inplace=True)\n\nlogs=['Departure Delay in Minutes','Arrival Delay in Minutes'] #log transform due to distribution shape\nfor l in logs:\n    train[l] = np.log(1+train[l])\n    test[l] = np.log(1+test[l])\ntrain=pd.get_dummies(train,drop_first=True) #encoding categorical variables\ntest =pd.get_dummies(test,drop_first=True)\nytrain=(ytrain=='satisfied').astype(int) #encoding ys\nytest=(ytest=='satisfied').astype(int)\ntrain.drop('Arrival Delay in Minutes',axis=1,inplace=True)\ntest.drop('Arrival Delay in Minutes',axis=1,inplace=True)\nfrom sklearn.preprocessing import StandardScaler\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T18:37:45.692979Z","iopub.execute_input":"2022-07-25T18:37:45.693388Z","iopub.status.idle":"2022-07-25T18:37:46.134404Z","shell.execute_reply.started":"2022-07-25T18:37:45.693352Z","shell.execute_reply":"2022-07-25T18:37:46.13306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn import metrics\n#https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\nimport random\nrandom.seed(42)\nnames = [\n    \"LR\",\n    \"KNN\",\n    \"DTree\",\n    \"RF\",\n    \"ADA\"\n]\n\nclassifiers = [\n    LogisticRegression(),\n    KNeighborsClassifier(n_neighbors=10, weights='distance'),\n    DecisionTreeClassifier(criterion = 'entropy', max_depth = 20, splitter = 'random'),\n    RandomForestClassifier(random_state=42, max_depth= 80, n_estimators=300, max_features=3),\n    AdaBoostClassifier(base_estimator=RandomForestClassifier(),learning_rate=0.5,n_estimators=200)\n]\n\ntrain = StandardScaler().fit_transform(train)\ntest = StandardScaler().fit_transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T17:55:05.923572Z","iopub.execute_input":"2022-07-25T17:55:05.92396Z","iopub.status.idle":"2022-07-25T17:55:05.965406Z","shell.execute_reply.started":"2022-07-25T17:55:05.923932Z","shell.execute_reply":"2022-07-25T17:55:05.96443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfor i,c in enumerate(classifiers): #roc curves from https://www.statology.org/plot-roc-curve-python/\n    t = time.time()\n    c.fit(train,ytrain)\n    y_pred_proba=c.predict_proba(test)[::,1]\n    print(names[i],time.time()-t)\n    fpr, tpr, _ = metrics.roc_curve(ytest,  y_pred_proba)\n    plt.figure()\n    #create ROC curve\n    plt.plot(fpr,tpr)\n    line = np.linspace(0,1,100)\n    plt.plot(line,line)\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.grid()\n    plt.title(names[i])\n    plt.show() #0,0,37,17","metadata":{"execution":{"iopub.status.busy":"2022-07-25T18:00:38.829401Z","iopub.execute_input":"2022-07-25T18:00:38.829789Z","iopub.status.idle":"2022-07-25T18:02:56.167197Z","shell.execute_reply.started":"2022-07-25T18:00:38.82976Z","shell.execute_reply":"2022-07-25T18:02:56.166329Z"},"trusted":true},"execution_count":null,"outputs":[]}]}